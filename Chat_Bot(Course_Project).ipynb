{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chat-Bot(Course_Project).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1zChixgtrVAt"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    train_data =  pickle.load(fp)\n",
        "\n",
        "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    test_data =  pickle.load(fp)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqnHtkQL66DB",
        "outputId": "aea5804b-c3ef-4879-ae0d-55cc6457e24e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(train_data[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aos8_5-r674D",
        "outputId": "a24dcade-1e9f-48b0-bc77-614961cf11f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(train_data[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DcYue5d669ye",
        "outputId": "8a594ff7-8b6b-4092-a036-74c078489974"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Is Sandra in the hallway ?'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wZ6uFmu66_6i",
        "outputId": "0736c81d-74d0-4118-b222-4d79dfbd2601"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'no'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set()\n",
        "all_data = test_data + train_data\n",
        "for story, question , answer in all_data:\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))\n",
        "\n",
        "vocab.add('no')\n",
        "vocab.add('yes')\n",
        "\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVwNXm3-7Bhp",
        "outputId": "3da207cd-45f1-43d2-ab6c-97ee9c0f4abc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences\n",
        "max_story_len = max([len(data[0]) for data in all_data])\n",
        "max_question_len = max([len(data[1]) for data in all_data])"
      ],
      "metadata": {
        "id": "ewdT3i-S7L5A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab) + 1"
      ],
      "metadata": {
        "id": "8P9lLD2ZW0Tq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vectorizing the data\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)\n",
        "\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyZ3zyzW7TeP",
        "outputId": "970fd55d-2c95-420e-eb7a-60c906582f9b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 7,\n",
              " '?': 8,\n",
              " 'apple': 5,\n",
              " 'back': 22,\n",
              " 'bathroom': 18,\n",
              " 'bedroom': 33,\n",
              " 'daniel': 27,\n",
              " 'discarded': 16,\n",
              " 'down': 30,\n",
              " 'dropped': 29,\n",
              " 'football': 11,\n",
              " 'garden': 34,\n",
              " 'got': 2,\n",
              " 'grabbed': 17,\n",
              " 'hallway': 23,\n",
              " 'in': 3,\n",
              " 'is': 20,\n",
              " 'john': 32,\n",
              " 'journeyed': 21,\n",
              " 'kitchen': 15,\n",
              " 'left': 6,\n",
              " 'mary': 25,\n",
              " 'milk': 9,\n",
              " 'moved': 26,\n",
              " 'no': 1,\n",
              " 'office': 35,\n",
              " 'picked': 12,\n",
              " 'put': 36,\n",
              " 'sandra': 10,\n",
              " 'the': 37,\n",
              " 'there': 4,\n",
              " 'to': 28,\n",
              " 'took': 31,\n",
              " 'travelled': 14,\n",
              " 'up': 13,\n",
              " 'went': 19,\n",
              " 'yes': 24}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)"
      ],
      "metadata": {
        "id": "ALWxIXTb7a4v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "metadata": {
        "id": "RAbhUxXB7c-j"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_story_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0BED-X47ebe",
        "outputId": "bdef63ed-c281-49a7-f2fa-06c65d3094a2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_story_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7rMgWtx7hkH",
        "outputId": "5122bdb8-f37c-45e6-bab3-203ba79657a4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#functionalise vectorization\n",
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        "    '''\n",
        "    INPUT: \n",
        "    \n",
        "    data: consisting of Stories,Queries,and Answers\n",
        "    word_index: word index dictionary from tokenizer\n",
        "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
        "    max_question_len: length of the longest question (used for pad_sequences function)\n",
        "\n",
        "\n",
        "    OUTPUT:\n",
        "    \n",
        "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
        "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
        "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
        "    \n",
        "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
        "    '''\n",
        "   \n",
        "    # X = STORIES\n",
        "    X = []\n",
        "    # Xq = QUERY/QUESTION\n",
        "    Xq = []\n",
        "    # Y = CORRECT ANSWER\n",
        "    Y = []\n",
        "    \n",
        "    for story, query, answer in data:\n",
        "        \n",
        "        # Grab the word index for every word in story\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        # Grab the word index for every word in query\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "        \n",
        "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
        "        # Index 0 is reserved so we're going to use + 1\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "        \n",
        "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
        "        #\n",
        "        y[word_index[answer]] = 1\n",
        "        \n",
        "        # Append each set of story,query, and answer to their respective holding lists\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "        \n",
        "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "        \n",
        "    # RETURN TUPLE FOR UNPACKING\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ],
      "metadata": {
        "id": "7fI09GT97jR8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)\n",
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "metadata": {
        "id": "HzhFs5vV8xIV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHxrKgpM8zdt",
        "outputId": "c9592d3f-fa38-48b1-d0bb-7f9e3aa69e06"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 37, 33,  7],\n",
              "       [ 0,  0,  0, ..., 37, 34,  7],\n",
              "       [ 0,  0,  0, ..., 37, 34,  7],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 37,  5,  7],\n",
              "       [ 0,  0,  0, ..., 37, 34,  7],\n",
              "       [ 0,  0,  0, ...,  5,  4,  7]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amCbisOK83Tf",
        "outputId": "e4c9fd12-512c-4138-a566-1c10be9f3231"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[20, 32,  3, 37, 15,  8],\n",
              "       [20, 32,  3, 37, 15,  8],\n",
              "       [20, 32,  3, 37, 34,  8],\n",
              "       ...,\n",
              "       [20, 25,  3, 37, 33,  8],\n",
              "       [20, 10,  3, 37, 34,  8],\n",
              "       [20, 25,  3, 37, 34,  8]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answers_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxZReOVE840w",
        "outputId": "0343c114-dbca-42af-c7bb-4ca3fbcda85f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM\n",
        "\n",
        "#placeholder for inputs\n",
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))\n",
        "\n",
        "#building end to end memory network\n",
        "\n",
        "#input encoder m\n",
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)\n",
        "\n",
        "#input encoder c\n",
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)\n",
        "\n",
        "#question encoder\n",
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)\n",
        "\n",
        "#encoding the sequences\n",
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)\n",
        "\n",
        "#Use dot product to compute the match between first input vector seq and the query\n",
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)\n",
        "\n",
        "#Add this match matrix with the second input vector sequence\n",
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)\n",
        "\n",
        "#concatenate\n",
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9D3cCLr86TE",
        "outputId": "53295c06-f466-4382-cb0d-d6efabb69ca0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 6, 220), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)\n",
        "\n",
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
        "\n",
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "IlIzZvF1PrIN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIGz8XmsPz5E",
        "outputId": "3819c473-a94a-4fb8-c7a4-610850716a8f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 156)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 6)]          0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, None, 64)     2432        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_3 (Sequential)      (None, 6, 64)        2432        ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 156, 6)       0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_3[0][0]']           \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 156, 6)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, None, 6)      228         ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 156, 6)       0           ['activation[0][0]',             \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 6, 156)       0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 6, 220)       0           ['permute[0][0]',                \n",
            "                                                                  'sequential_3[0][0]']           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 32)           32384       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 32)           0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 38)           1254        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 38)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "# filename = 'chatbot_120_epochs.h5'\n",
        "# model.load_weights(filename)\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=200,validation_data=([inputs_test, queries_test], answers_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poWqxp3zP2Uv",
        "outputId": "a9df253d-e0b1-4302-9ca6-0bebcd99e680"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "313/313 [==============================] - 10s 13ms/step - loss: 0.8648 - accuracy: 0.4900 - val_loss: 0.6948 - val_accuracy: 0.4970\n",
            "Epoch 2/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.7001 - accuracy: 0.4996 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
            "Epoch 3/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.6951 - accuracy: 0.5043 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
            "Epoch 4/200\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.6943 - accuracy: 0.5083 - val_loss: 0.6952 - val_accuracy: 0.5030\n",
            "Epoch 5/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.6953 - accuracy: 0.4971 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
            "Epoch 6/200\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.6944 - accuracy: 0.5034 - val_loss: 0.6940 - val_accuracy: 0.5030\n",
            "Epoch 7/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.6951 - accuracy: 0.4944 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 8/200\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.6938 - accuracy: 0.5056 - val_loss: 0.6945 - val_accuracy: 0.4970\n",
            "Epoch 9/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.6943 - accuracy: 0.5026 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 10/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.6945 - accuracy: 0.5037 - val_loss: 0.6942 - val_accuracy: 0.4970\n",
            "Epoch 11/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.6946 - accuracy: 0.4958 - val_loss: 0.6937 - val_accuracy: 0.4830\n",
            "Epoch 12/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.6943 - accuracy: 0.5071 - val_loss: 0.6937 - val_accuracy: 0.4960\n",
            "Epoch 13/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.6899 - accuracy: 0.5271 - val_loss: 0.6838 - val_accuracy: 0.5700\n",
            "Epoch 14/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.6724 - accuracy: 0.5749 - val_loss: 0.6659 - val_accuracy: 0.5860\n",
            "Epoch 15/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.6508 - accuracy: 0.6072 - val_loss: 0.6342 - val_accuracy: 0.6390\n",
            "Epoch 16/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.6089 - accuracy: 0.6764 - val_loss: 0.5729 - val_accuracy: 0.7180\n",
            "Epoch 17/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.5550 - accuracy: 0.7222 - val_loss: 0.4871 - val_accuracy: 0.7800\n",
            "Epoch 18/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.5081 - accuracy: 0.7616 - val_loss: 0.4613 - val_accuracy: 0.7810\n",
            "Epoch 19/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.4775 - accuracy: 0.7797 - val_loss: 0.4422 - val_accuracy: 0.7910\n",
            "Epoch 20/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.4510 - accuracy: 0.7923 - val_loss: 0.4271 - val_accuracy: 0.7920\n",
            "Epoch 21/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.4371 - accuracy: 0.8007 - val_loss: 0.4181 - val_accuracy: 0.7960\n",
            "Epoch 22/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.4100 - val_accuracy: 0.7950\n",
            "Epoch 23/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.4201 - accuracy: 0.8020 - val_loss: 0.4226 - val_accuracy: 0.7920\n",
            "Epoch 24/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.4160 - accuracy: 0.8064 - val_loss: 0.4105 - val_accuracy: 0.8000\n",
            "Epoch 25/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.4061 - accuracy: 0.8096 - val_loss: 0.4017 - val_accuracy: 0.8030\n",
            "Epoch 26/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3997 - accuracy: 0.8106 - val_loss: 0.4054 - val_accuracy: 0.7930\n",
            "Epoch 27/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3951 - accuracy: 0.8153 - val_loss: 0.3926 - val_accuracy: 0.8000\n",
            "Epoch 28/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3963 - accuracy: 0.8113 - val_loss: 0.3948 - val_accuracy: 0.8000\n",
            "Epoch 29/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3941 - accuracy: 0.8129 - val_loss: 0.4011 - val_accuracy: 0.7990\n",
            "Epoch 30/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.3868 - accuracy: 0.8172 - val_loss: 0.4011 - val_accuracy: 0.8010\n",
            "Epoch 31/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.3807 - accuracy: 0.8199 - val_loss: 0.4045 - val_accuracy: 0.8030\n",
            "Epoch 32/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.3837 - accuracy: 0.8220 - val_loss: 0.3857 - val_accuracy: 0.8060\n",
            "Epoch 33/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3776 - accuracy: 0.8209 - val_loss: 0.3978 - val_accuracy: 0.8070\n",
            "Epoch 34/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.3718 - accuracy: 0.8221 - val_loss: 0.3743 - val_accuracy: 0.8250\n",
            "Epoch 35/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.3689 - accuracy: 0.8312 - val_loss: 0.3807 - val_accuracy: 0.8160\n",
            "Epoch 36/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3643 - accuracy: 0.8320 - val_loss: 0.3645 - val_accuracy: 0.8280\n",
            "Epoch 37/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.3605 - accuracy: 0.8303 - val_loss: 0.3733 - val_accuracy: 0.8160\n",
            "Epoch 38/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3558 - accuracy: 0.8404 - val_loss: 0.3618 - val_accuracy: 0.8330\n",
            "Epoch 39/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3505 - accuracy: 0.8423 - val_loss: 0.3569 - val_accuracy: 0.8380\n",
            "Epoch 40/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3494 - accuracy: 0.8454 - val_loss: 0.3551 - val_accuracy: 0.8300\n",
            "Epoch 41/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3446 - accuracy: 0.8454 - val_loss: 0.3695 - val_accuracy: 0.8280\n",
            "Epoch 42/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3499 - accuracy: 0.8430 - val_loss: 0.3715 - val_accuracy: 0.8310\n",
            "Epoch 43/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3433 - accuracy: 0.8483 - val_loss: 0.3731 - val_accuracy: 0.8290\n",
            "Epoch 44/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3459 - accuracy: 0.8466 - val_loss: 0.3578 - val_accuracy: 0.8460\n",
            "Epoch 45/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3400 - accuracy: 0.8476 - val_loss: 0.3509 - val_accuracy: 0.8350\n",
            "Epoch 46/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3397 - accuracy: 0.8483 - val_loss: 0.3645 - val_accuracy: 0.8260\n",
            "Epoch 47/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3399 - accuracy: 0.8482 - val_loss: 0.3564 - val_accuracy: 0.8440\n",
            "Epoch 48/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3396 - accuracy: 0.8490 - val_loss: 0.3516 - val_accuracy: 0.8420\n",
            "Epoch 49/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3365 - accuracy: 0.8505 - val_loss: 0.3592 - val_accuracy: 0.8230\n",
            "Epoch 50/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3366 - accuracy: 0.8514 - val_loss: 0.3610 - val_accuracy: 0.8350\n",
            "Epoch 51/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3357 - accuracy: 0.8525 - val_loss: 0.3665 - val_accuracy: 0.8390\n",
            "Epoch 52/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3289 - accuracy: 0.8546 - val_loss: 0.3641 - val_accuracy: 0.8300\n",
            "Epoch 53/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3259 - accuracy: 0.8522 - val_loss: 0.3738 - val_accuracy: 0.8280\n",
            "Epoch 54/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3316 - accuracy: 0.8531 - val_loss: 0.3618 - val_accuracy: 0.8280\n",
            "Epoch 55/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3286 - accuracy: 0.8568 - val_loss: 0.3459 - val_accuracy: 0.8320\n",
            "Epoch 56/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3268 - accuracy: 0.8556 - val_loss: 0.3574 - val_accuracy: 0.8390\n",
            "Epoch 57/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3279 - accuracy: 0.8579 - val_loss: 0.3678 - val_accuracy: 0.8420\n",
            "Epoch 58/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3247 - accuracy: 0.8572 - val_loss: 0.3577 - val_accuracy: 0.8260\n",
            "Epoch 59/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3262 - accuracy: 0.8565 - val_loss: 0.3554 - val_accuracy: 0.8450\n",
            "Epoch 60/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3272 - accuracy: 0.8590 - val_loss: 0.3564 - val_accuracy: 0.8400\n",
            "Epoch 61/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3202 - accuracy: 0.8620 - val_loss: 0.3471 - val_accuracy: 0.8400\n",
            "Epoch 62/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3245 - accuracy: 0.8566 - val_loss: 0.3492 - val_accuracy: 0.8330\n",
            "Epoch 63/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3212 - accuracy: 0.8538 - val_loss: 0.3803 - val_accuracy: 0.8370\n",
            "Epoch 64/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3204 - accuracy: 0.8577 - val_loss: 0.3784 - val_accuracy: 0.8330\n",
            "Epoch 65/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3206 - accuracy: 0.8642 - val_loss: 0.3544 - val_accuracy: 0.8390\n",
            "Epoch 66/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3130 - accuracy: 0.8667 - val_loss: 0.3764 - val_accuracy: 0.8330\n",
            "Epoch 67/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3201 - accuracy: 0.8593 - val_loss: 0.3722 - val_accuracy: 0.8270\n",
            "Epoch 68/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3157 - accuracy: 0.8588 - val_loss: 0.3598 - val_accuracy: 0.8390\n",
            "Epoch 69/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3110 - accuracy: 0.8620 - val_loss: 0.3506 - val_accuracy: 0.8390\n",
            "Epoch 70/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3143 - accuracy: 0.8616 - val_loss: 0.3675 - val_accuracy: 0.8290\n",
            "Epoch 71/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3091 - accuracy: 0.8668 - val_loss: 0.3657 - val_accuracy: 0.8290\n",
            "Epoch 72/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3142 - accuracy: 0.8667 - val_loss: 0.3611 - val_accuracy: 0.8420\n",
            "Epoch 73/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3071 - accuracy: 0.8649 - val_loss: 0.3613 - val_accuracy: 0.8340\n",
            "Epoch 74/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3044 - accuracy: 0.8653 - val_loss: 0.3576 - val_accuracy: 0.8280\n",
            "Epoch 75/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3097 - accuracy: 0.8622 - val_loss: 0.3561 - val_accuracy: 0.8370\n",
            "Epoch 76/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3114 - accuracy: 0.8665 - val_loss: 0.3661 - val_accuracy: 0.8340\n",
            "Epoch 77/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2987 - accuracy: 0.8726 - val_loss: 0.3797 - val_accuracy: 0.8300\n",
            "Epoch 78/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3036 - accuracy: 0.8694 - val_loss: 0.3835 - val_accuracy: 0.8340\n",
            "Epoch 79/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2995 - accuracy: 0.8697 - val_loss: 0.3719 - val_accuracy: 0.8360\n",
            "Epoch 80/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2997 - accuracy: 0.8718 - val_loss: 0.3740 - val_accuracy: 0.8320\n",
            "Epoch 81/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3042 - accuracy: 0.8688 - val_loss: 0.3642 - val_accuracy: 0.8350\n",
            "Epoch 82/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3021 - accuracy: 0.8675 - val_loss: 0.3659 - val_accuracy: 0.8370\n",
            "Epoch 83/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2945 - accuracy: 0.8707 - val_loss: 0.3676 - val_accuracy: 0.8350\n",
            "Epoch 84/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2984 - accuracy: 0.8708 - val_loss: 0.3705 - val_accuracy: 0.8340\n",
            "Epoch 85/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3014 - accuracy: 0.8688 - val_loss: 0.4018 - val_accuracy: 0.8280\n",
            "Epoch 86/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2963 - accuracy: 0.8729 - val_loss: 0.3899 - val_accuracy: 0.8260\n",
            "Epoch 87/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2924 - accuracy: 0.8723 - val_loss: 0.3890 - val_accuracy: 0.8310\n",
            "Epoch 88/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2888 - accuracy: 0.8730 - val_loss: 0.3633 - val_accuracy: 0.8330\n",
            "Epoch 89/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2959 - accuracy: 0.8753 - val_loss: 0.3853 - val_accuracy: 0.8290\n",
            "Epoch 90/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2925 - accuracy: 0.8751 - val_loss: 0.3735 - val_accuracy: 0.8300\n",
            "Epoch 91/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2864 - accuracy: 0.8755 - val_loss: 0.3797 - val_accuracy: 0.8270\n",
            "Epoch 92/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2848 - accuracy: 0.8735 - val_loss: 0.3773 - val_accuracy: 0.8250\n",
            "Epoch 93/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2827 - accuracy: 0.8748 - val_loss: 0.4017 - val_accuracy: 0.8280\n",
            "Epoch 94/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2868 - accuracy: 0.8743 - val_loss: 0.3788 - val_accuracy: 0.8240\n",
            "Epoch 95/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2873 - accuracy: 0.8781 - val_loss: 0.3928 - val_accuracy: 0.8350\n",
            "Epoch 96/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2902 - accuracy: 0.8751 - val_loss: 0.3718 - val_accuracy: 0.8340\n",
            "Epoch 97/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2837 - accuracy: 0.8772 - val_loss: 0.3975 - val_accuracy: 0.8310\n",
            "Epoch 98/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2766 - accuracy: 0.8798 - val_loss: 0.3924 - val_accuracy: 0.8310\n",
            "Epoch 99/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2774 - accuracy: 0.8828 - val_loss: 0.3929 - val_accuracy: 0.8300\n",
            "Epoch 100/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2785 - accuracy: 0.8803 - val_loss: 0.3786 - val_accuracy: 0.8290\n",
            "Epoch 101/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2775 - accuracy: 0.8814 - val_loss: 0.3699 - val_accuracy: 0.8280\n",
            "Epoch 102/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2773 - accuracy: 0.8794 - val_loss: 0.3811 - val_accuracy: 0.8350\n",
            "Epoch 103/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2779 - accuracy: 0.8816 - val_loss: 0.3921 - val_accuracy: 0.8290\n",
            "Epoch 104/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2693 - accuracy: 0.8851 - val_loss: 0.4047 - val_accuracy: 0.8340\n",
            "Epoch 105/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2706 - accuracy: 0.8826 - val_loss: 0.3894 - val_accuracy: 0.8240\n",
            "Epoch 106/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2670 - accuracy: 0.8845 - val_loss: 0.4220 - val_accuracy: 0.8220\n",
            "Epoch 107/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2655 - accuracy: 0.8823 - val_loss: 0.4199 - val_accuracy: 0.8300\n",
            "Epoch 108/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2698 - accuracy: 0.8860 - val_loss: 0.3945 - val_accuracy: 0.8280\n",
            "Epoch 109/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2638 - accuracy: 0.8857 - val_loss: 0.4091 - val_accuracy: 0.8300\n",
            "Epoch 110/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2620 - accuracy: 0.8860 - val_loss: 0.4293 - val_accuracy: 0.8340\n",
            "Epoch 111/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2642 - accuracy: 0.8866 - val_loss: 0.3957 - val_accuracy: 0.8330\n",
            "Epoch 112/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2627 - accuracy: 0.8864 - val_loss: 0.4219 - val_accuracy: 0.8270\n",
            "Epoch 113/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2630 - accuracy: 0.8886 - val_loss: 0.3972 - val_accuracy: 0.8250\n",
            "Epoch 114/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2630 - accuracy: 0.8875 - val_loss: 0.4018 - val_accuracy: 0.8320\n",
            "Epoch 115/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2589 - accuracy: 0.8895 - val_loss: 0.3996 - val_accuracy: 0.8360\n",
            "Epoch 116/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2605 - accuracy: 0.8906 - val_loss: 0.4126 - val_accuracy: 0.8270\n",
            "Epoch 117/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2582 - accuracy: 0.8893 - val_loss: 0.4004 - val_accuracy: 0.8320\n",
            "Epoch 118/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2553 - accuracy: 0.8894 - val_loss: 0.4099 - val_accuracy: 0.8340\n",
            "Epoch 119/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2557 - accuracy: 0.8898 - val_loss: 0.3991 - val_accuracy: 0.8320\n",
            "Epoch 120/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2561 - accuracy: 0.8915 - val_loss: 0.4120 - val_accuracy: 0.8320\n",
            "Epoch 121/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2525 - accuracy: 0.8921 - val_loss: 0.4135 - val_accuracy: 0.8300\n",
            "Epoch 122/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2554 - accuracy: 0.8902 - val_loss: 0.4520 - val_accuracy: 0.8310\n",
            "Epoch 123/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2522 - accuracy: 0.8938 - val_loss: 0.4200 - val_accuracy: 0.8280\n",
            "Epoch 124/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2467 - accuracy: 0.8947 - val_loss: 0.4379 - val_accuracy: 0.8280\n",
            "Epoch 125/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2480 - accuracy: 0.8921 - val_loss: 0.4625 - val_accuracy: 0.8350\n",
            "Epoch 126/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2542 - accuracy: 0.8910 - val_loss: 0.4141 - val_accuracy: 0.8260\n",
            "Epoch 127/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2473 - accuracy: 0.8956 - val_loss: 0.4310 - val_accuracy: 0.8270\n",
            "Epoch 128/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2505 - accuracy: 0.8939 - val_loss: 0.4316 - val_accuracy: 0.8240\n",
            "Epoch 129/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2468 - accuracy: 0.8904 - val_loss: 0.4146 - val_accuracy: 0.8250\n",
            "Epoch 130/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2529 - accuracy: 0.8921 - val_loss: 0.4484 - val_accuracy: 0.8290\n",
            "Epoch 131/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2472 - accuracy: 0.8957 - val_loss: 0.4276 - val_accuracy: 0.8330\n",
            "Epoch 132/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2463 - accuracy: 0.8968 - val_loss: 0.4517 - val_accuracy: 0.8240\n",
            "Epoch 133/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2465 - accuracy: 0.8964 - val_loss: 0.4366 - val_accuracy: 0.8220\n",
            "Epoch 134/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2447 - accuracy: 0.8983 - val_loss: 0.4637 - val_accuracy: 0.8290\n",
            "Epoch 135/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2451 - accuracy: 0.9004 - val_loss: 0.4414 - val_accuracy: 0.8290\n",
            "Epoch 136/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2436 - accuracy: 0.8988 - val_loss: 0.4271 - val_accuracy: 0.8260\n",
            "Epoch 137/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2404 - accuracy: 0.9003 - val_loss: 0.4685 - val_accuracy: 0.8270\n",
            "Epoch 138/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2378 - accuracy: 0.8998 - val_loss: 0.4422 - val_accuracy: 0.8260\n",
            "Epoch 139/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2365 - accuracy: 0.9020 - val_loss: 0.4678 - val_accuracy: 0.8220\n",
            "Epoch 140/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2316 - accuracy: 0.9008 - val_loss: 0.4399 - val_accuracy: 0.8290\n",
            "Epoch 141/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2348 - accuracy: 0.9033 - val_loss: 0.4592 - val_accuracy: 0.8330\n",
            "Epoch 142/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2340 - accuracy: 0.8999 - val_loss: 0.4527 - val_accuracy: 0.8290\n",
            "Epoch 143/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2413 - accuracy: 0.8995 - val_loss: 0.4290 - val_accuracy: 0.8230\n",
            "Epoch 144/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2379 - accuracy: 0.9030 - val_loss: 0.4279 - val_accuracy: 0.8330\n",
            "Epoch 145/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2371 - accuracy: 0.9012 - val_loss: 0.4343 - val_accuracy: 0.8310\n",
            "Epoch 146/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2300 - accuracy: 0.9061 - val_loss: 0.4576 - val_accuracy: 0.8270\n",
            "Epoch 147/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2300 - accuracy: 0.9056 - val_loss: 0.4608 - val_accuracy: 0.8310\n",
            "Epoch 148/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2320 - accuracy: 0.9034 - val_loss: 0.4684 - val_accuracy: 0.8320\n",
            "Epoch 149/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2313 - accuracy: 0.9045 - val_loss: 0.4742 - val_accuracy: 0.8300\n",
            "Epoch 150/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2197 - accuracy: 0.9083 - val_loss: 0.4595 - val_accuracy: 0.8260\n",
            "Epoch 151/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2346 - accuracy: 0.9025 - val_loss: 0.4800 - val_accuracy: 0.8320\n",
            "Epoch 152/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2227 - accuracy: 0.9070 - val_loss: 0.4395 - val_accuracy: 0.8260\n",
            "Epoch 153/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2261 - accuracy: 0.9076 - val_loss: 0.4341 - val_accuracy: 0.8310\n",
            "Epoch 154/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2159 - accuracy: 0.9120 - val_loss: 0.4810 - val_accuracy: 0.8230\n",
            "Epoch 155/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2270 - accuracy: 0.9063 - val_loss: 0.4960 - val_accuracy: 0.8310\n",
            "Epoch 156/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2216 - accuracy: 0.9099 - val_loss: 0.4851 - val_accuracy: 0.8310\n",
            "Epoch 157/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2196 - accuracy: 0.9102 - val_loss: 0.4989 - val_accuracy: 0.8270\n",
            "Epoch 158/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2256 - accuracy: 0.9074 - val_loss: 0.4955 - val_accuracy: 0.8300\n",
            "Epoch 159/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2170 - accuracy: 0.9119 - val_loss: 0.5354 - val_accuracy: 0.8300\n",
            "Epoch 160/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2129 - accuracy: 0.9111 - val_loss: 0.4773 - val_accuracy: 0.8390\n",
            "Epoch 161/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2201 - accuracy: 0.9115 - val_loss: 0.4737 - val_accuracy: 0.8340\n",
            "Epoch 162/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2109 - accuracy: 0.9133 - val_loss: 0.4779 - val_accuracy: 0.8400\n",
            "Epoch 163/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2131 - accuracy: 0.9132 - val_loss: 0.4999 - val_accuracy: 0.8330\n",
            "Epoch 164/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2147 - accuracy: 0.9147 - val_loss: 0.4840 - val_accuracy: 0.8300\n",
            "Epoch 165/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2079 - accuracy: 0.9172 - val_loss: 0.5075 - val_accuracy: 0.8270\n",
            "Epoch 166/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2155 - accuracy: 0.9115 - val_loss: 0.5174 - val_accuracy: 0.8240\n",
            "Epoch 167/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2153 - accuracy: 0.9131 - val_loss: 0.5332 - val_accuracy: 0.8320\n",
            "Epoch 168/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2041 - accuracy: 0.9182 - val_loss: 0.4697 - val_accuracy: 0.8370\n",
            "Epoch 169/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2113 - accuracy: 0.9137 - val_loss: 0.4424 - val_accuracy: 0.8270\n",
            "Epoch 170/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2144 - accuracy: 0.9157 - val_loss: 0.4693 - val_accuracy: 0.8350\n",
            "Epoch 171/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2142 - accuracy: 0.9114 - val_loss: 0.4875 - val_accuracy: 0.8280\n",
            "Epoch 172/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2061 - accuracy: 0.9166 - val_loss: 0.5409 - val_accuracy: 0.8350\n",
            "Epoch 173/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1987 - accuracy: 0.9185 - val_loss: 0.4894 - val_accuracy: 0.8330\n",
            "Epoch 174/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2065 - accuracy: 0.9186 - val_loss: 0.4891 - val_accuracy: 0.8300\n",
            "Epoch 175/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1975 - accuracy: 0.9189 - val_loss: 0.4793 - val_accuracy: 0.8330\n",
            "Epoch 176/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2022 - accuracy: 0.9200 - val_loss: 0.5045 - val_accuracy: 0.8270\n",
            "Epoch 177/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1982 - accuracy: 0.9244 - val_loss: 0.5421 - val_accuracy: 0.8230\n",
            "Epoch 178/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1936 - accuracy: 0.9201 - val_loss: 0.5090 - val_accuracy: 0.8260\n",
            "Epoch 179/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2004 - accuracy: 0.9206 - val_loss: 0.5277 - val_accuracy: 0.8310\n",
            "Epoch 180/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1990 - accuracy: 0.9197 - val_loss: 0.5217 - val_accuracy: 0.8260\n",
            "Epoch 181/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1880 - accuracy: 0.9240 - val_loss: 0.5417 - val_accuracy: 0.8280\n",
            "Epoch 182/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1948 - accuracy: 0.9240 - val_loss: 0.5090 - val_accuracy: 0.8370\n",
            "Epoch 183/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2011 - accuracy: 0.9202 - val_loss: 0.4977 - val_accuracy: 0.8390\n",
            "Epoch 184/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1958 - accuracy: 0.9229 - val_loss: 0.5098 - val_accuracy: 0.8320\n",
            "Epoch 185/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1897 - accuracy: 0.9265 - val_loss: 0.5064 - val_accuracy: 0.8280\n",
            "Epoch 186/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1865 - accuracy: 0.9261 - val_loss: 0.5131 - val_accuracy: 0.8390\n",
            "Epoch 187/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1863 - accuracy: 0.9265 - val_loss: 0.5321 - val_accuracy: 0.8320\n",
            "Epoch 188/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1914 - accuracy: 0.9234 - val_loss: 0.5072 - val_accuracy: 0.8410\n",
            "Epoch 189/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1806 - accuracy: 0.9257 - val_loss: 0.5046 - val_accuracy: 0.8410\n",
            "Epoch 190/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1788 - accuracy: 0.9299 - val_loss: 0.5037 - val_accuracy: 0.8390\n",
            "Epoch 191/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1799 - accuracy: 0.9291 - val_loss: 0.5228 - val_accuracy: 0.8410\n",
            "Epoch 192/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1756 - accuracy: 0.9316 - val_loss: 0.4991 - val_accuracy: 0.8360\n",
            "Epoch 193/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1758 - accuracy: 0.9309 - val_loss: 0.5228 - val_accuracy: 0.8400\n",
            "Epoch 194/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1704 - accuracy: 0.9334 - val_loss: 0.5086 - val_accuracy: 0.8440\n",
            "Epoch 195/200\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1714 - accuracy: 0.9344 - val_loss: 0.5915 - val_accuracy: 0.8380\n",
            "Epoch 196/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1782 - accuracy: 0.9314 - val_loss: 0.5046 - val_accuracy: 0.8450\n",
            "Epoch 197/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1734 - accuracy: 0.9302 - val_loss: 0.5085 - val_accuracy: 0.8390\n",
            "Epoch 198/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1710 - accuracy: 0.9320 - val_loss: 0.4870 - val_accuracy: 0.8450\n",
            "Epoch 199/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1685 - accuracy: 0.9346 - val_loss: 0.5728 - val_accuracy: 0.8370\n",
            "Epoch 200/200\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1661 - accuracy: 0.9361 - val_loss: 0.5826 - val_accuracy: 0.8320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'chatbot_200_epochs.h5'\n",
        "model.save(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNiGIMP0QQ6p",
        "outputId": "2e40f8ba-9cef-47da-f182-e9f4da804390"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "iqC_0YV-QTjZ",
        "outputId": "eb5e469c-b32b-4170-9a4f-24281c2d6c6c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(filename)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ],
      "metadata": {
        "id": "NOlkjxABQvpw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story =' '.join(word for word in test_data[0][0])\n",
        "print(story)\n",
        "query = ' '.join(word for word in test_data[0][1])\n",
        "print(query)\n",
        "print(\"True Test Answer from Data is:\",test_data[0][2])\n",
        "pred_results[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOPVUTasQwn8",
        "outputId": "5007fc61-d124-4842-fa1c-ca173e132fcf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mary got the milk there . John moved to the bedroom .\n",
            "Is John in the kitchen ?\n",
            "True Test Answer from Data is: no\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.8447715e-16, 9.9998248e-01, 1.7374173e-16, 1.5413464e-16,\n",
              "       1.5751560e-16, 1.7177262e-16, 1.5085675e-16, 1.5919311e-16,\n",
              "       1.6112925e-16, 1.7719552e-16, 1.9237327e-16, 1.6856144e-16,\n",
              "       1.8316304e-16, 1.7194766e-16, 1.7415312e-16, 1.4212881e-16,\n",
              "       1.5488909e-16, 1.5523156e-16, 1.7838648e-16, 1.6796385e-16,\n",
              "       1.5142985e-16, 1.7469009e-16, 1.5181796e-16, 1.7707052e-16,\n",
              "       1.7548989e-05, 1.5010591e-16, 1.5864992e-16, 1.4486239e-16,\n",
              "       1.5933832e-16, 1.8729074e-16, 1.6254669e-16, 1.3873263e-16,\n",
              "       1.4824342e-16, 1.6489621e-16, 1.8112377e-16, 1.4059895e-16,\n",
              "       1.9944148e-16, 1.6644962e-16], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YiihxdLQy7W",
        "outputId": "653958f5-ecd0-42ae-871c-a5a40b708c3f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  0.9999825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remember you can only use words from the existing vocab\n",
        "# Note the whitespace of the periods\n",
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "my_question = \"Is the football in the garden ?\"\n",
        "mydata = [(my_story.split(),my_question.split(),'yes')]\n",
        "my_story,my_ques,my_ans = vectorize_stories(mydata)\n",
        "pred_results = model.predict(([ my_story, my_ques]))"
      ],
      "metadata": {
        "id": "X16erAclTdi0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kae-7AFvTwJB",
        "outputId": "3f44c6c9-3d18-4718-9393-8e9d1a42e19a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  yes\n",
            "Probability of certainty was:  0.82454896\n"
          ]
        }
      ]
    }
  ]
}